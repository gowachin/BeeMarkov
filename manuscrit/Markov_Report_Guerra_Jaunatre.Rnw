\documentclass[10pt,a4paper,notitlepage,colorinlistoftodos]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Template pour rendus Master
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[utf8]{inputenc} %encodage
\usepackage[T1]{fontenc}

\usepackage[square,sort,comma,numbers]{natbib} % bibliography
\setcitestyle{authoryear,open={(},close={)}}
\renewcommand{\bibsection}{}

\usepackage[french]{babel} % langue
% add '\-' to create custom hypernation if a word is difficult to cut or :
\hyphenation{geo-graphique}

%mise en page générale
\usepackage{geometry}
%\geometry{a4paper} % format de feuille
\geometry{top=1.5cm, bottom=1.5cm, left=1.5cm, right=1.5cm} %marges
\usepackage{mathptmx} % Police Times si compilateur pdfLatex

\usepackage{times}

\linespread{1.5} % interligne
\usepackage{fancyhdr} %en tete et pied de page
\usepackage{lastpage}  %marche pas chez julia
\pagestyle{plain} 

\usepackage{lscape} % page en landscape

\usepackage{multicol}
\setlength{\columnsep}{1cm}

\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
  
\usepackage{hyperref,url} % lien cliquables
\hypersetup{
colorlinks = true,
linkcolor = blue,
citecolor = RoyalBlue,
urlcolor = black
} % https://tex.stackexchange.com/questions/50747/options-for-appearance-of-links-in-hyperref
\usepackage{lipsum} %Lorem ipsum

\usepackage{wrapfig} %position d'images dans le texte
\usepackage{graphicx, subcaption, setspace, booktabs, wrapfig}

\usepackage[table,dvipsnames]{xcolor}

\usepackage{caption}
\DeclareCaptionType{annexe}[Annexe][Liste d'annexes] % rajout pour captions annexes
\DeclareCaptionType{web}[Web][Sites Web] % rajout pour mettre des captions web

%\usepackage{todonotes} % notes et commentaires
\usepackage[disable]{todonotes} % pour supprimer les commentaires lors de la compil

\usepackage[export]{adjustbox}

\usepackage[para,online,flushleft]{threeparttable}

%%%%%%%%%%%% skip an all paragraphe, between this bornes %%%%%%%%%%%%%%%%%%
%\iffalse
%\fi

%%%%%%%%%%%%%%%%%%%%%%%%%% Code R   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{listings}
\usepackage{color}
%http://latexcolor.com/ 
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{cerulean}{rgb}{0.0, 0.48, 0.65}
\definecolor{beaublue}{rgb}{0.95, 0.95, 0.95}
\definecolor{amber}{rgb}{1.0, 0.25, 0.0}
\definecolor{indiagreen}{rgb}{0.07, 0.53, 0.03}
\definecolor{number}{rgb}{0.01, 0.01, 0.01}

\lstset{language = R,
    basicstyle=\footnotesize,
    breaklines=true,
    keepspaces=true,
    firstnumber=1,
    numbers=left, % where line-numbers; possible values (none, left, right)
    numbersep=5pt,  % how far the line-numbers are from the code
    numberstyle=\color{number},
    deletekeywords={_,/,C,troll,approx,min},
    backgroundcolor=\color{beaublue},   
    commentstyle=\color{indiagreen},
    keywordstyle=\color{amber},
    stringstyle=\color{cerulean}
    }
    
%\begin{lstlisting}
%  %%%% put the R code here %%%%
%\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%% LATEX DIFF %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% use terminal: latexdiff ancientfile.tex newfile.tex > revisionfile.tex

%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF     PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

%%%%%%%%%%%%%%%%%%%%%%%%%%% nouvelles commandes spécifique au doc %%%%%%%%%%%%%%%%%%
\newcommand{\clade}[1]{clade `#1'}

\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}}
\renewcommand*\contentsname{Table des matières}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Page de garde
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\SweaveOpts{concordance=TRUE}

%\twocolumn[
\begin{figure}
   \centering
    \begin{minipage}{.75\textwidth}
    \begin{center}
    {\Large Modélisation de la structure de chromosomes de souris par modèles de Markov cachés.}
    \end{center}
    %\vspace{\baselineskip}
    %\setlength{\parskip}{\smallskipamount}
    \rule{7em}{.4pt}\par
    %\todo[color = red]{put ellie}
     Julia Guerra $^1$, Maxime Jaunatre $^2$, Ellie Tideswell $^3$ | Master 2 BEE Grenoble \par 
     \href{mailto:Julia.Julia@etu.univ-grenoble-alpes.fr}{Mail $^1$}, \href{mailto:maxime.jaunatre@etu.univ-grenoble-alpes.fr}{Mail $^2$} \href{mailto:etideswell@hotmail.co.uk}{Mail $^3$}| \today \par 
     %\href{mailto:Julia.Julia@etu.univ-grenoble-alpes.fr,maxime.jaunatre@etu.univ-grenoble-alpes.fr}{Mail} | \today
\end{minipage}
\end{figure}

\hrule
%]
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Todo list pour travail en cours
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
\listoftodos
\hrule\bigskip
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Table des matières
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage
%\tableofcontents
%\thispagestyle{empty}

%\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BODY
% chunks options
% | option   |      meaning     |  default |
% |:--------:|:-------------:|:------:|
% | echo |  indique si le code doit apparaître ou non | TRUE |
% | eval |    indique si le code doit être exécuté ou non.   |   TRUE |
% | fig | indique si la figure doit être générée ou non. |    FALSE |
% | pdf | indique si un pdf de la figure doit être généré ou non. |   FALSE |
% | ref.label | rappelle un chunk pour le reproduire (avec le nom du chunk en value) |   FALSE |
\SweaveOpts{echo = FALSE} % results = hide
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<packages , echo = FALSE, eval=TRUE, results=hide>>=
library(xtable)
library(ggplot2)
library(reshape)
# library(plyr)
# library(MASS)
# library(ResourceSelection)
# library(ggpubr)
# library(tidyr)

if("BeeMarkov" %in% installed.packages()) {
  library(BeeMarkov)
}else{
  # library(devtools)
  # install_github("gowachin/BeeMarkov")
  # library(BeeMarkov)
}

library(seqinr)
rerun = FALSE
@

<<working, eval = F>>=
setwd("manuscrit")

@
% 4 pages max

\begin{multicols}{2}

%\section*{Introduction}
L’avancée des techniques de séquençage a permis d’obtenir de grandes quantités d’informations génomiques. Durant ces dernières années, la génétique a embrassé les outils mathématiques de modélisation, parvenant à une caractérisation statistique des données de séquençage. Cette approche a permis  de décrire avec précision les motifs observés dans des régions étudiées , et de prédire leurs présences dans des séquences encore inconnues \citep{Wu2010}. Une des méthodes les plus connues dans ce domaine est l’utilisation des chaînes de Markov, introduites premièrement par \cite{Churchill1992} pour l’analyse de séquences génomiques puis par \cite{Durbin1998} pour la détection de régions CGI. 

Dans le génome des deutérostomiens, la fréquence du dinucléotide C-G est moins importante qu’attendu sous une distribution aléatoire indépendante des quatre bases azotées. Ceci est une conséquence des mécanismes de protection contre la mutation spontanée du génome. Cependant, dans certaines régions de l’ADN nommées îlots CpG (ou CGI)  ce processus de mutation est évolutivement reprimé et donc la fréquence des dinucléotides C-G est donc plus élevée; par exemple aux alentours de certains promoteurs \citep{Saxonov2006a,Wu2010, Deaton2011}. 

La grande variabilité dans la taille, la composition et l’emplacement de ces CGI rend difficile leurs définitions et donc l’établissement d’un algorithme unique permettant leurs détections indubitable \citep{Wu2010}. Ainsi, les modèles de Markov permettent de modéliser les fréquences des nucléotides en fonction de séquences déjà connues; ces séquences contenant ou non des CGI. En supplément des chaînes de Markov simples, il existe aussi les chaînes de Markov cachées (HMM, \cite{Churchill1992}): ces dernières décrivent de nombreux processus réels qui suivent un modèle de Markov,  mais qui ne sont pas observables. Une chaîne de Markov cachée permettrait donc l’utilisation d’un seul modèle pour identifier un nucléotide (l’observation) et si ce dernier est à l’intérieur d’un îlot CpG ou non (aussi appelé l’état de la région). Les HMM permettent ainsi d’augmenter la résolution de l’analyse, c’est-à-dire de détecter l’emplacement des régions CGI à l’intérieur des séquences.

\section*{Matériel et méthodes}

\subsection*{Modèles de Markov simples}

%\subsection*{construire un modèle (markov simple)}
Les modèles de Markov réalisés dans cette étude ont été construits à partir de deux jeux de séquences de  souris (Mus musculus). Ces jeux de séquences avaient été caractérisés en avance comme contenant des îlots CpG (on notera “CpG+”), ou ne contenant pas d’îlots CpG (“CpG-”). Les deux jeux de séquences “app”, pour la construction des modèles CpG+ et CpG- ,contenaient 1160 et 5755 séquences respectivement. Des jeux supplémentaires “test” également caractérisés comme CpG+ ou CpG- (1163 et 5137 séquences) ont servi à évaluer la performance des modèles. 
 
Dans un premier temps, les fréquences relatives d’observation des bases A, C, G, T ont été calculées pour la totalité des séquences de chaque jeu de données “app” (R,  fonction \verb|count| du package \verb|seqinr|; \cite{Charif2007}).  Ces données ont permis de construire la matrices de probabilité A du modèle d’ordre 0 (M0). Le terme “ordre” fait référence au nombre de bases précédentes conditionnant la probabilité de présence de la base étudiée. De cette manière, le M0 considère la probabilité d’occurrence de chaque base comme une variable aléatoire (équation \ref{eq:11}) dont les probabilités d’occurrence (équation \ref{eq:12})) sont différentes. En plus, des résultats différents sont attendus en fonction de la nature CpG+ ou CpG- des séquences; c’est pourquoi deux matrices de probabilité A+ et A- ont été construites, provenant respectivements des comptages du jeu CpG+ et CpG-.

Le modèle de Markov d’ordre 1 (M1) rassemble les occurrences de chaque base en fonction de la base précédente. Les matrices de transition q1+ et q1- sont matrices 4x4 qui ont été donc construites à partir des comptages de chaque couple de bases. Vu qu’elle ne peut pas dépendre d’une base précédente, la probabilité d’occurrence de chaque base initiale a été considérée comme une variable aléatoire (équation \ref{eq:21}) à probabilités équivalentes (équation \ref{eq:22}). Ce protocole de construction de modèle a été refait pour l’ordre 2, obtenant une matrice 16x4. Pareil pour l’ordre  3 (matrice 64 x 4), l’ordre 4 \dots jusqu’à l’ordre 5. Pour les modèles d’ordre supérieur 0, les lignes de la matrice ont été rangées de sorte que la somme de chaque ligne soit égal à 1, à cause de la nature conditionnelle des probabilités, comme dans l'exemple suivant (table \ref{tab:trans}. 

\begin{equation}
Y \in B;  B = {a,c,g,t}
\label{eq:11}
\end{equation}
\begin{equation}
P(Y_i = k) \forall k \in B
\label{eq:12}
\end{equation}
\begin{equation}
X \in B;  B = {a,c,g,t}
\label{eq:21}
\end{equation}
\begin{equation}
P(A) = P(C) = P(G) = P(T) = P (X \in B) = \frac{1}{4}
\label{eq:22}
\end{equation}

<<transition , echo = F, eval=T, results=hide>>=
transition <- function(file, # fichier
                       l_word = 1, # longueur des mots
                       n_seq = 1, # Nombre de sequences a analyser
                       log = TRUE,
                       type = "") {
  seq <-seqinr::read.fasta(file)
  Nseq <- length(seq)
  
  if (Nseq < n_seq) { # check if user want to input too many seq in the matrix learning
    stop(paste("n_seq is larger than the number of sequence in this file ( ", Nseq, " sequences for this file).", sep = ""))
  }
  
  l <- sapply(seq, length)
  if (l_word > min(l) | l_word >= 10) {
    stop("This is really too much for me, abort!!!")
  }

  tmp <-seqinr::count(seq[[1]], l_word) + 1 # add 1 occurence to have at least 1 obs
  
  cat(paste("      ============ Training model M",type,l_word," ============        \n", sep = ""))
  pb <- utils::txtProgressBar(min = 0, max = n_seq, style = 3)
  for (i in 2:n_seq) {
    utils::setTxtProgressBar(pb, i)
    
    tmp <- tmp +seqinr::count(seq[[i]], l_word)
  }
  close(pb)
  
  # # alternativ way, slower but prettier
  # cat(paste("      ============ Training model M",type,l_word," ============        \n", sep = ""))
  # l_count = function(Seq,n = l_word){count(Seq,n)} 
  # tmp <- rowSums(sapply(seq,l_count))
  
  if (l_word>1) {
    i <- 1
    wind = 4 
    for(j in 0:((length(tmp)/wind)-1)){
      tmp[(1+wind*j):(wind+wind*j)] <- tmp[(1+wind*j):(wind+wind*j)] * 4^(i-1) / sum(tmp[(1+wind*j):(wind+wind*j)] )
    }
    cat('      ============ Computing conditionnal probabilities ============        \n')
  } else {
    tmp = tmp / sum(tmp)
  }
  # possibility to compute without log
  if (log) {
    tmp = log(tmp)
  }
  return(tmp)
}

mP <-transition(file = "../raw_data/mus_cpg_app.fa", n_seq = 1160, l_word = 2, log = F)

mP <- matrix(mP, byrow = TRUE, ncol = 4, dimnames = list(unique(substr(names(mP),1,1)),unique(substr(names(mP),1,1))))

matable <- xtable(x = mP , label = "tab:trans")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/tab_trans.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")
@

\begin{wraptable}{r}{0.4\linewidth}
  \begin{center}
  \input{fig/tab_trans.tex}
  \end{center}
  \caption{Matrice de transition du modèle CpG+ d'ordre 1}
  \label{tab:trans}
\end{wraptable}  

A partir des matrices de transition, on peut calculer la log-Vraisemblance d’une séquence sous un modèle MX correspondant comme la somme du log de la probabilité de premières bases (région de taille égale à l’ordre) avec la somme du produit de la matrice de transition par la matrice d’occurence des mots dans la séquence (voir équation \ref{eq:logV}).

\end{multicols}

\begin{equation}
P_+(Sequence) = log\left[P_{initial}(mot_{initial})\right] + \sum_{i=1}^{n = 4^{ordre+1}} log\left[P_i(mot_{i}) \cdot N_i(mot_{i})\right]
\label{eq:logV}
\end{equation}

\begin{multicols}{2}
\subsection*{Choix du meilleur modele}
La performance du M1 a été testée sur les deux jeux de séquences de test. La log-vraisemblance de chaque séquence a été calculé pour chaque modèle (CpG+ et CpG-) et la séquence est donc associée à l’état pour lequel la log-vraisemblance est la plus grande. Pour le jeu de données CpG+, les séquences caractérisées comme CpG+ sont considérées comme vrais positifs (VP) et les séquences caractérisées CpG- comme faux négatifs (FN). Pour le jeu de données CpG-, les séquences caractérisées comme CpG+ sont considérées comme faux positifs (FP) et celles caractérisées comme CpG- comme vrais négatifs (VN). Le même protocole a été suivi pour tester la performance des modèles 1 à 6.
		 
La spécificité et la sensibilité de chaque modèle ont été calculées à partir de ces résultats, selon les équations  illustrées en \ref{eq:sensi_speci} et \ref{eq:sensi_speci2}.

\begin{equation}
Sensibility = \frac{VP}{VP+FN}% \\ Specificity = \frac{VN}{VN+FP}
\label{eq:sensi_speci}
\end{equation}
\begin{equation}
Specificity = \frac{VN}{VN+FP}
\label{eq:sensi_speci2}
\end{equation}

% \begin{Multline}
% E(x_0, y_0)=  \int^{+\infty}_{-\infty} \ , exp \left( az \bigg[ \frac{ax_0}{3z} + \frac{y^2-2y_0 y}{2z} \bigg] \right)\\ \cdot E(x,y)dxdy
%  \end{Multline}
% \label{Equation_1}

<<threshold , echo = F, eval=T, results=hide>>=
quality <- function(file, # fichier
                    pos_training = NULL, # file to train with for positive
                    neg_training = NULL, # file to train with for negative
                    trans_pos = NULL, #transition matrice pos
                    trans_neg = NULL, #transition matrice pos
                    l_word_pos = 1, # word lenght for transition table positif
                    l_word_neg = 1, # word length for transition table negatif
                    n_train = 1, # number of sequences to train with
                    n_seq = 1, # number of sequences to analyse
                    quiet = FALSE
){
  if(is.null(c(trans_pos,trans_neg))){
    trans_pos <-transition(file = pos_training, n_seq = n_train, l_word = l_word_pos, type ="+")
    trans_neg <- transition(file = neg_training, n_seq = n_train, l_word = l_word_neg, type = "-")
  } 
  
  seq <-seqinr::read.fasta(file)
  Nseq <- length(seq)
  
  if(Nseq < n_seq){ # check if user want to input too many seq in the matrix learning
    stop(paste("n_seq is larger than the number of sequence in this file ( ",Nseq," sequences for this file).", sep = ""))
  }
  
  result <- data.frame(VP = rep(FALSE,n_seq),
                       FN = rep(TRUE,n_seq),
                       pos = rep(NA,n_seq),
                       neg = rep(NA,n_seq)
  )
  
  p_init_pos = log(1/4^l_word_pos)
  p_init_neg = log(1/4^l_word_neg)
  
  if(!quiet) {cat('      ============ Computing sensi and speci for the test sequences ============       \n')
    pb <- utils::txtProgressBar(min = 0, max = n_seq, style = 3)}
  for(i in 1:n_seq){
    if(!quiet) utils::setTxtProgressBar(pb, i)
    n_word_pos <-seqinr::count(seq[[i]], l_word_pos)
    n_word_neg <-seqinr::count(seq[[i]], l_word_neg)
    result$pos[i] <- p_init_pos + sum( trans_pos * n_word_pos )
    result$neg[i] <- p_init_neg + sum( trans_neg * n_word_neg )
    if(result$pos[i] > result$neg[i]){
      result$VP[i] <- TRUE ; result$FN[i] <- FALSE 
    } else { 
      result$VP[i] <- FALSE ; result$FN[i] <- TRUE
    }
  }
  if(!quiet) close(pb)
  
  tmp <- colSums(result[,1:2])
  return(tmp)
}

threshold <- function(pos_test, # fichier
                     neg_test,
                     pos_training, # file to train with for positive
                     neg_training, # file to train with for negative
                     pos_seq = c(1:2),
                     neg_seq = c(1:2),
                     n_train = 1, # number of sequences to train with
                     n_seq = 1 # number of sequences to analyse
){
  
  # choix =utils::menu(c("yes","no"),
  #              title = "You will launch long computation, do you wish to procede further ?")
  # if (choix ==1) cat("\n      ============ Go take a good coffee ============       \n\n")
  # if (choix ==2) stop("You stopped the computations")
  
  
  trans_pos <- list()
  trans_neg <- list()
  
  cat('\n      ============ Training modeles ============       \n\n')
  for(i in pos_seq){
    trans_pos[[i]] <- transition(file = pos_training, n_seq = n_train, l_word = i, type = "+")
  }
  cat('\n')
  for(j in neg_seq){
    trans_neg[[j]] <- transition(file = neg_training, n_seq = n_train, l_word = j, type = "-")
  }
  
  cat('\n      ============ Training modeles ============       \n\n')    
  sensi <- speci <- matrix(rep(0,length(pos_seq)*length(neg_seq)),ncol = length(pos_seq),nrow = length(neg_seq))
  for(i in pos_seq){
    for(j in neg_seq){
      cat('\n')
      cat(paste("      ============ Model M+ (",i,"/",j,") ============        \n", sep = ""))
      pos <- quality(file = pos_test, # fichier
                     trans_pos = trans_pos[[i]], #transition matrice pos
                     trans_neg = trans_neg[[j]], #transition matrice neg
                     l_word_pos = i, # transition table positif
                     l_word_neg = j, # transition table negatif
                     n_train = n_train, # number of sequences to train with
                     n_seq = n_seq, # number of sequences to analyse
                     quiet = TRUE
      )
      cat(paste("      ============ Model M- (",i,"/",j,") ============        \n", sep = ""))
      neg <- quality(file = neg_test, # fichier
                     trans_pos = trans_pos[[i]], #transition matrice pos
                     trans_neg = trans_neg[[j]], #transition matrice neg
                     l_word_pos = i, # transition table positif
                     l_word_neg = j, # transition table negatif
                     n_train = n_train, # number of sequences to train with
                     n_seq = n_seq, # number of sequences to analyse
                     quiet = TRUE
      )
      
      sensi[i,j] <- pos[1] / sum(pos)
      speci[i,j] <- neg[2] / sum(neg)
      
    }
  }
  
  cat(paste("      ============ Come back from your coffee ============        \n", sep = ""))
  colnames(sensi) <- colnames(speci) <- paste("-",neg_seq, sep="")
  rownames(sensi) <- rownames(speci) <- paste("+",pos_seq, sep="")
  
  final <-list(sensi,speci) ; names(final) = c("sensi","speci")
  
  return(final)
}

@


<<seuil , echo = F, eval=T, results=hide>>=
if("final.RData" %in% list.files("fig/") && !rerun){
  load("fig/final.RData")
}else{
  final <- threshold("../raw_data/mus_cpg_test.fa", # fichier
  "../raw_data/mus_tem_test.fa",
  "../raw_data/mus_cpg_app.fa", # file to train with for positive
  "../raw_data/mus_tem_app.fa", # file to train with for negative
  pos_seq = c(1:6),
  neg_seq = c(1:6),
  n_train = 1160, # number of sequences to train with
  n_seq = 1163 # number of sequences to analyse
)
save(final,file = "fig/final.RData")
}

table <- cbind(melt(final$sensi), melt(final$speci)[, 3])
colnames(table) <- c("M", "m", "Sensi", "Speci")
table$score <- table$Sensi + table$Speci

visual <- ggplot(table, aes(M, m)) +
  geom_raster(aes(fill = score), hjust = 0.5, vjust = 0.5, interpolate = FALSE) +
  geom_contour(aes(z = score)) + xlab("CpG+") + ylab("CpG-")
visual
ggsave('visual.pdf', plot = visual, device = "pdf", path = 'fig/',scale = 3, width = 7, height = 4, units = "cm", limitsize = T)
rm(visual)

table[which(table$tot == max(table$tot)),]
@

% \begin{wrapfigure}{r}{0.6\linewidth}
% \begin{center}
% \includegraphics[width=\linewidth]{fig/visual.pdf}
% \end{center}
% \caption{Evolution du score de sensibilité + spécificité selon les ordre de modèles}
% \label{fig:sensispeci}
% \end{wrapfigure}

Ce processus, répété pour toutes les combinaisons de Mi+/Mj- (avec i et j allant de 0 à 5), a permis de connaître la meilleure combinaison de modèle. Pour l’obtenir, les données de sensibilité et spécificité pour les modèles ont été sommés entre elles. La combinaison d’ordres portant la valeur maximale étant la valeur (5,4) de la matrice; les calculs de la chaîne de Markov cachée ont été réalisés sur un modèle d’ordre 5 pour les séquences CpG+ et un modèle d’ordre 4 pour les séquences CpG-. La figure \ref{fig:sensispeci} montre les résultats de sensibilité et spécificité mentionnées ici.

\end{multicols}

\begin{figure*}[!ht]%{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=\linewidth]{fig/visual.pdf}
\end{center}
\caption{Evolution du score de sensibilité + spécificité selon les ordre de modèles}
\label{fig:sensispeci}
\end{figure*}

\begin{multicols}{2}

Modèles de Markov cachés
Les bases mathématiques de l’analyse des îlots CGI parmi des HMM dans cet étude suit le protocole décrit dans \cite{Churchill1992}. Pour la construction des HMM, il a été nécessaire de calculer la probabilité de transition entre état CpG+ et état CpG- à l’intérieur d’une séquence. Les valeurs de cette matrice de transition 2x2 contenant d’états ont été obtenues à partir de la bibliographie, en prenant compte de la longueur moyenne des îlots CpG. Cette matrice (\ref{tab:trans_mod}) s'ajoute donc à la matrice des probabilités d’occurrence de chaque base (ou combinaison de bases) et à la matrice d’occurrence des bases initiales.  


<<trans_mod , echo = F, eval=T, results=hide>>=
  l_c <- 1 / 1000
  l_nc <- 1 / 125000
  
   trans_mod <- log(matrix(c(
    1 - l_c, l_nc,
    l_c, 1 - l_nc
  ),
  ncol = 2, nrow = 2 , dimnames = list(c("M+","M-"),c("M+","M-"))
  ))

matable <- xtable(x = trans_mod , label = "tab:trans_mod")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/trans_mod.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")
@

\begin{wraptable}{r}{0.3\linewidth}
  \begin{center}
  \input{fig/trans_mod.tex}
  \end{center}
  \caption{Matrice de transition du modèle CpG+ d'ordre 1}
  \label{tab:trans_mod}
\end{wraptable}  

\subsection*{L’algorithme de Viterbi}

Afin de trouver la séquence optimale d’états qui correspond à une séquence donnée d’observations, il est possible d’utiliser une fenêtre glissante (un algorithme naïf), dans laquelle les log vraisemblances sont calculés pour des segments de bases d’une longueur donnée. Bien que facile à implémenter, les résultats (en terme des prédictions des CGI) dépendent de la taille de la fenêtre choisi, ceci peut représenter un biais de cette méthode.  Une façon alternative peut être l’algorithme de Viterbi, un exemple de la programmation dynamique, qui permet d’identifier la séquence qui maximise la probabilité de générer les observations 
\todo[inline, color = red]{Pardoux}. Le chemin le plus probable étant donné un modèle est déterminé via une procédure récursive. L’algorithme de Viterbi est décrit comme suit :

<<viterbi , echo = F,eval = T, results = hide>>=
viterbi <- function(file,
                    pos_training = "../raw_data/mus_cpg_app.fa", # file to train with for positive
                    neg_training = "../raw_data/mus_tem_app.fa", # file to train with for negative
                    l_word_pos = 1,
                    l_word_neg = 1,
                    n_train = 1160,
                    n_ana = 1,
                    l_c = 1000, # length coding
                    l_nc = 125000 # length non-coding
) {
  trans_pos <- transition(file = pos_training, n_seq = n_train, l_word = l_word_pos, type = "+")
  trans_neg <- transition(file = neg_training, n_seq = n_train, l_word = l_word_neg, type = "-")
  
  seq <- seqinr::read.fasta(file)
  if (n_ana > 1) stop("Analysis for multiple files is not implemented yet")
  
  raw_seq <- seq[[1]]
  long <- length(raw_seq)
  
  beg <- max(l_word_pos, l_word_neg)
  
  # compute p_initial and transition matrix for markov
  pos_init <- neg_init <- log(0.5)
  l_c <- 1 / l_c
  l_nc <- 1 / l_nc
  
  trans_mod <- log(matrix(c(
    1 - l_c, l_nc,
    l_c, 1 - l_nc
  ),
  ncol = 2, nrow = 2
  ))
  colnames(trans_mod) <- rownames(trans_mod) <- c("c", "nc")
  
  # initialisation
  ncol <- 7
  proba <- matrix(rep(NA, long * ncol), ncol = ncol)
  colnames(proba) <- c("M+", "M-", "model", "length", "rep_length", "begin", "end")
  
  # time explode if it is not a matrix anymore !!!
  # proba <- as.data.frame(proba)
  
  # old version is v2 takes too long
  # v1 = function(){
  # trans_pos[which(names(trans_pos)==paste(raw_seq[(beg-l_word_pos+1):beg],collapse = ""))]
  # }
  # v2 = function(){
  # min(count(raw_seq[(beg-l_word_pos+1):beg], l_word_pos) * trans_pos)
  # }
  # system.time(v1())
  # system.time(v2())
  
  # compute first base and initiate Viterbi
  proba[beg, "M+"] <- trans_pos[which(names(trans_pos) == paste(raw_seq[(beg - l_word_pos + 1):beg], collapse = ""))] + pos_init
  proba[beg, "M-"] <- trans_neg[which(names(trans_neg) == paste(raw_seq[(beg - l_word_neg + 1):beg], collapse = ""))] + neg_init
  if (proba[beg, "M+"] > proba[beg, "M-"]) {
    proba[beg, "model"] <- 1
  } else {
    proba[beg, "model"] <- 2
  }
  proba[beg, c("length", "rep_length")] <- 1
  tmp <- proba[beg, c(6, 7)] <- beg
  proba[1:beg - 1, "rep_length"] <- beg - 1
  proba[1:beg - 1, "model"] <- 3
  proba[1, "begin"] <- 1
  proba[beg - 1, c(4, 7)] <- beg - 1
  
  beg <- beg + 1
  cat("\n      ============ Viterbi is running ============       \n\n")
  pb <- utils::txtProgressBar(min = beg, max = long, style = 3)
  for (i in beg:long) {
    utils::setTxtProgressBar(pb, i)
    
    # proba d'avoir la base sous M
    pM <- trans_pos[which(names(trans_pos) == paste(raw_seq[(i - l_word_pos + 1):i], collapse = ""))] + max(
      proba[i - 1, "M+"] + trans_mod[1, 1],
      proba[i - 1, "M-"] + trans_mod[2, 1]
    )
    
    # proba d'avoir la base sous m
    pm <- trans_neg[which(names(trans_neg) == paste(raw_seq[(i - l_word_neg + 1):i], collapse = ""))] + max(
      proba[i - 1, "M-"] + trans_mod[2, 2],
      proba[i - 1, "M+"] + trans_mod[1, 2]
    )
    
    proba[i, "M+"] <- pM
    proba[i, "M-"] <- pm
    
    if (proba[i, "M+"] > proba[i, 2]) {
      proba[i, "model"] <- 1
    } else {
      proba[i, "model"] <- 2
    }
    # length information
    if (proba[i, "model"] == proba[i - 1, "model"]) {
      proba[i, "length"] <- proba[i - 1, "length"] + 1 # increase part length
      proba[i - 1, c(4, 7)] <- NA # erase length in previous ligne
    } else {
      proba[i, "length"] <- 1 # initiate new part length
      proba[i - 1, "end"] <- i - 1 # put end value of precedent part
      proba[c(tmp:(i - 1)), "rep_length"] <- proba[i - 1, "length"] # rep value of length for precedent part
      proba[i, "begin"] <- tmp <- i # put begin value of the actual part
    }
  }
  close(pb)
  
  # closing table
  proba[i, "end"] <- i # put end value of precedent part
  proba[c(tmp:(i)), "rep_length"] <- proba[i, "length"] # rep value of length for precedent part
  
  # add a column for the line number
  proba <- cbind(c(1:dim(proba)[1]), proba)
  colnames(proba)[1] <- "n"
  
  return(proba)
}
@


\subsection*{Smoothing} 
La technique de “Smoothing” représente une technique mathématique qui enlève la variabilité parmi les données, impliquant souvent la redistribution du poids entre des régions de haute probabilité, et des régions de “zéro probabilité” \todo[inline, color = red]{Boodidi 2007}. Dans le cadre de cette étude, le “Smoothing” revient donc à lisser la caractérisation des différentes régions en les ré-assignant selon 2 procédés successifs. 

<<smoothing , echo = F,eval = T, results = hide>>=
smoothing <- function(seq,
                      l_word_pos = 5,
                      l_word_neg = 4,
                      smooth_win = 10,
                      reject_win = 1) {
  beg <- max(l_word_pos, l_word_neg)

  # finding ambiguous regions which are shorter than a certain windows
  cat("      ============ Smoothing ============       \n")
  seq <- cbind(seq, seq[, 4])
  colnames(seq)[9] <- c("smoothed")
  seq[which(seq[, "rep_length"] <= smooth_win), "smoothed"] <- 3

  # old version is v1 takes too long
  # v1 = function(){
  #   cat("      ============ Smoothing boucle ============       \n")
  #   pb <- utils::txtProgressBar(min = 1, max = max(seq[, 1]), style = 3)
  #   for (i in 1:dim(seq)[1]) {
  #     utils::setTxtProgressBar(pb, i)
  #     if (seq[i, 6] <= smooth_win) {
  #       seq[i, "smoothed"] <- 3
  #     }
  #   }
  #   close(pb)
  # }
  # v2 = function(){
  #   seq[which(seq[, 6] <= smooth_win), "smoothed"] <- 3}
  # system.time(v1())
  # system.time(v2())
  
  # unified ambiguous regions
  seq <- cbind(seq, seq[, c(5:8)])
  colnames(seq)[10:13] <- paste("S_", colnames(seq[, c(10:13)]), sep = "")

  seq[beg, "S_length"] <- 1
  tmp <- seq[beg, c("S_begin", "S_end")] <- beg
  seq[-c(1:beg), c(10:13)] <- NA

  beg <- beg + 1
  cat("\n      ============ Smoothing length ============      \n")
  pb <- utils::txtProgressBar(min = beg - 1, max = dim(seq)[1], style = 3)
  for (i in beg:dim(seq)[1]) {
    utils::setTxtProgressBar(pb, i)
    if (seq[i, "smoothed"] == seq[i - 1, "smoothed"]) {
      seq[i, "S_length"] <- seq[i - 1, "S_length"] + 1 # increase part length
      seq[i - 1, c("S_length", "S_end")] <- NA # erase length in previous ligne
    } else {
      seq[i, "S_length"] <- 1 # initiate new part length
      seq[i - 1, "S_end"] <- i - 1 # put end value of precedent part
      seq[c(tmp:(i - 1)), "S_rep_length"] <- seq[i - 1, "S_length"] # rep value of length for precedent part
      seq[i, "S_begin"] <- tmp <- i # put begin value of the actual part
    }
  }
  close(pb)

  # closing table
  seq[i, 13] <- i # put end value of precedent part
  seq[c(tmp:(i)), 11] <- seq[i, 10] # rep value of length for precedent part
  
  # to reject some region and put arbitrary models on them
  if(reject_win > 1){
    colnames(seq)[10:13] <- paste("R_", colnames(seq[, c(10:13)]), sep = "")
    
    head(seq)
    
    cat("      ============ Rejecting ============      \n")
    # finding regions of length < reject_win between tho regions of same model. Changing the model to surrounding
    solo_l <-seq[which(seq[,"R_S_length"] %in% unique(seq[, "R_S_rep_length"])),c("smoothed","R_S_rep_length")]
    for(i in 2:(dim(solo_l)[1]-1)){
      if(solo_l[i-1,1]==solo_l[i+1,1] && solo_l[i,2] < reject_win && solo_l[i,1] == 3) {solo_l[i,1] <- solo_l[i-1,1]}
    }
    
    seq[,"smoothed"] <- rep(solo_l[,1],solo_l[,2])
    
    beg <- beg - 1
    
    seq[beg, "R_S_length"] <- 1
    tmp <- seq[beg, c("R_S_begin", "R_S_end")] <- beg
    seq[-c(1:beg), c(10:13)] <- NA
    
    beg <- beg + 1
    seq[-c(1:beg), c(10:13)] <- NA
    cat("\n      ============ Smoothing length after reject ============      \n")
    pb <- utils::txtProgressBar(min = beg - 1, max = dim(seq)[1], style = 3)
    for (i in beg:dim(seq)[1]) {
      utils::setTxtProgressBar(pb, i)
      if (seq[i, "smoothed"] == seq[i - 1, "smoothed"]) {
        seq[i, "R_S_length"] <- seq[i - 1, "R_S_length"] + 1 # increase part length
        seq[i - 1, c("R_S_length", "R_S_end")] <- NA # erase length in previous ligne
      } else {
        seq[i, "R_S_length"] <- 1 # initiate new part length
        seq[i - 1, "R_S_end"] <- i - 1 # put end value of precedent part
        seq[c(tmp:(i - 1)), "R_S_rep_length"] <- seq[i - 1, "R_S_length"] # rep value of length for precedent part
        seq[i, "R_S_begin"] <- tmp <- i # put begin value of the actual part
      }
    }
    close(pb)
    
    # closing table
    seq[i, 13] <- i # put end value of precedent part
    seq[c(tmp:(i)), 11] <- seq[i, 10] # rep value of length for precedent part
    
  }
  
  return(seq)
}
@

Dans un premier temps, les régions de longueur inférieur à un certain seuil (S) sont assignée à une nouvelle catégorie “Ambiguous”, en vert dans la figure \ref{fig:smoothing}. Cette première étape comporte également un algorithme qui compile ces nouvelles régions en une seule quand elles se suivent dans la séquence (voir bases 9 à 13), afin de mesurer la longueur de cette nouvelle région dont la catégorie est devenue unique.

\begin{wrapfigure}{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=\linewidth]{fig/smoothin_reject.png}
\end{center}
\caption{Evolution du score de sensibilité + spécificité selon les ordre de modèles}
\label{fig:smoothing}
\end{wrapfigure}

Le second procédé vérifie la longueur de ces nouvelles régions ambiguës et leurs situations sur la séquence. En effet, il arrive qu’une région de petite taille soit considérée comme ambiguë entre deux régions d’une même catégorie (voir base 5). On peut donc supposer qu’il s’agit de bruit et que cette région est probablement de la même catégorie que celles qui l’entoure. Ainsi, le second procédé de smoothing va ré-assigner des régions ambiguës si leurs tailles sont inférieures à un seuil et que les régions bordantes sont de même nature.
On note que l'algorithme de ‘Smoothing’ ne peut être utilisé qu’avec le second procédé, car en l’absence de régions ambiguës aucune ré-assignation vers CpG+ ou CpG- n’est possible. 

<<plot_resume , echo = F, eval=T, results=hide>>=
graph <- function(seq,colors = c("blue","red","green"),nrow = 3,ycol = 4){
  par(mfrow = c(nrow,1), mar = c(3,2,1,1))
  # c(5, 4, 4, 2)
  
  long <- max(seq[,1])/nrow
  for(i in 0:(nrow-1)){
    plot(x = seq[((1+long*i):(long+long*i)),1],
         y = seq[((1+long*i):(long+long*i)),ycol],
         col = colors[seq[((1+long*i):(long+long*i)),9]], xlab = " ", ylab = " ")
  }
  par(mfrow = c(1,1))
}

resume <- function(seq){
  beg <- seq[which(!is.na(seq[,12])),12] 
  end <- seq[which(!is.na(seq[,13])),13]
  long <- seq[which(!is.na(seq[,10])),10]
  model <- seq[which(!is.na(seq[,10])),9]
  length(beg) ; length((end)) ; length(long) ; length(model)
  
  table <- data.frame(beg,end,long,model)
  return(table)
}
@

\section*{Résultats}
\subsection*{mus1}
<<mus1 , echo = F, eval=T, results=hide>>=
if("mus1.RData" %in% list.files("fig/") && !rerun){
  load("fig/mus1.RData")
}else{
mus1 <- viterbi(file = "../raw_data/mus1.fa",
  l_word_pos = 5,
  l_word_neg = 4
)
save(mus1,file = "fig/mus1.RData")
}

mus1 <- smoothing(mus1,5,4,60, 40)

jpeg("fig/mus1_s.jpg", width = 836, height = 496)
# 2. Create the plot
graph(mus1,nrow = 3, ycol = 9)
# 3. Close the file
dev.off()

mus1_t <- resume(mus1)

matable <- xtable(x = mus1_t , label = "tab:mus1_t")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/mus1_t.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")
@



Après un viterbi pour le modèle M5+/M4-, et un smoothing avec S = 60 et R = 40, le chromosome de souris numero 1 met en évidence \Sexpr{summary(as.factor(mus1_t$model))[1]} régions CpG+ contre \Sexpr{summary(as.factor(mus1_t$model))[2]} régions CpG-, avec un grand déséquilibre de longueur entre ces régions. Ainsi, les régions CpG+ font en moyenne \Sexpr{round(mean(mus1_t[which(mus1_t$model==1),3]),3)} contre \Sexpr{round(mean(mus1_t[which(mus1_t$model==2),3]),3)} pour les régions CpG-. A contrario, les régions ambigües sont de faibles longueurs (\Sexpr{round(mean(mus1_t[which(mus1_t$model==3),3]),3)}), valeur proche du seuil de smoothing comme attendu. 

Du fait de la grande longueur des régions CpG-, on observe que les régions CpG+ sont groupées et séparées par d'autres régions CpG- de taille limitée.

L'ensemble des résultats pour le chromosome 1 est disponible en annexe.

\subsection*{mus2}
<<mus2 , echo = F, eval=T, results=hide>>=
if("mus2.RData" %in% list.files("fig/") && !rerun){
  load("fig/mus2.RData")
}else{
mus2 <- viterbi(file = "../raw_data/mus2.fa",
  l_word_pos = 5,
  l_word_neg = 4
)
save(mus2,file = "fig/mus2.RData")
}

mus2 <- smoothing(mus2,5,4,60, 40)

jpeg("fig/mus2_s.jpg", width = 836, height = 496)
# 2. Create the plot
graph(mus2,nrow = 3, ycol = 9)
# 3. Close the file
dev.off()

mus2_t <- resume(mus2)

matable <- xtable(x = mus2_t , label = "tab:mus2_t")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/mus2_t.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")
@
Après un viterbi pour le modèle M5+/M4-, et un smoothing avec S = 60 et R = 40, le chromosome de souris numero 2 met en évidence \Sexpr{summary(as.factor(mus2_t$model))[1]} régions CpG+ contre \Sexpr{summary(as.factor(mus2_t$model))[2]} régions CpG-, avec un grand déséquilibre de longueur entre ces régions. Ainsi, les régions CpG+ font en moyenne \Sexpr{round(mean(mus2_t[which(mus2_t$model==1),3]),3)} contre \Sexpr{round(mean(mus2_t[which(mus2_t$model==2),3]),3)} pour les régions CpG-.

Par rapport au chromosome numero 1, les régions CpG+ dont plus longues et centrées sur la fin du chromosome en une région bien définie.

L'ensemble des résultats pour le chromosome 2 est disponible en annexe.
\subsection*{mus3}
<<mus3 , echo = F, eval=T, results=hide>>=
if("mus3.RData" %in% list.files("fig/") && !rerun){
  load("fig/mus3.RData")
}else{
mus3 <- viterbi(file = "../raw_data/mus3.fa",
  l_word_pos = 5,
  l_word_neg = 4
)
save(mus3,file = "fig/mus3.RData")
}

mus3 <- smoothing(mus3,5,4,60, 40)

jpeg("fig/mus3_s.jpg", width = 836, height = 496)
# 2. Create the plot
graph(mus3,nrow = 3, ycol = 9)
# 3. Close the file
dev.off()

mus3_t <- resume(mus3)

matable <- xtable(x = mus3_t , label = "tab:mus3_t")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/mus3_t.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")
@
Après un viterbi pour le modèle M5+/M4-, et un smoothing avec S = 60 et R = 40, le chromosome de souris numero 1 met en évidence \Sexpr{summary(as.factor(mus3_t$model))[1]} régions CpG+ contre \Sexpr{summary(as.factor(mus3_t$model))[2]} régions CpG-, avec un grand déséquilibre de longueur entre ces régions. Ainsi, les régions CpG+ font en moyenne \Sexpr{round(mean(mus3_t[which(mus3_t$model==1),3]),3)} contre \Sexpr{round(mean(mus3_t[which(mus3_t$model==2),3]),3)} pour les régions CpG-.

Concernant le chromosome 3, il présente très peu de régions CpG+ et elles sont de faible longueurs.

L'ensemble des résultats pour le chromosome 3 est disponible en annexe.

\section*{Discussion}

L'implémentation d'un algorithme de Viterbi a permis la caractérisation rapide de trois chromosomes de souris et la détection de régions CpG+. Ce genre d'outils montre donc son intéret pour une analyse rapide de données génomiques. On note cependant que la dernière partie de l'algorithme (smoothing) a été implémentée de manière sommaire et qu'une étude approfondie des seuils sur les résultats manque. La prochaine étape serait donc de tester différents seuils de smoothing (variant S et R), afin d'optimiser les résultats sur chaque chromosome.

L’apprentissage de nos modèles est ici relativement rapide car le jeu de donnée d'entraînement est limité et nos modèles encore simplifiés. Cependant, il est important de noter que des modèles plus complexes entraînent des temps de calculs d’autant plus important. Dans ce contexte, il est donc important de souligner que tout n’a pas été fait pour optimiser l’apprentissage de nos modèles. Il reste encore possible de paralléliser différentes étapes de l’apprentissages ou du test des modèles différents. Une solution encore plus avancée serait de changer de langage de programmation afin de produire un algorithme plus efficace que celui proposé ici sour \verb|R|.

Afin d'améliorer la performance de notre modèle, il serait raisonnable de raffiner la sélection des CGI identifiés, selon des propriétés connus des CGIs, tels que le contenu de GC, la fraction de CpG et un seuil de longueur \citep{Lan2009}. De nombreux études ont relevé la fausse identification dans les CGI de petites quantités des nucléotides CpG+, identifiées comme CpG-. Un seuil minimal de longueur entre des nucléotides CpG+ en voisinage pourrait résoudre ce problème, donc un ‘smoothing’ plus dynamique ou les paramètres changent en fonction de l’état dans lequel la nucléotide se situe (CpG+ ou CpG-). Les CGI contiennent également une ratio élevé de G/C, ce qui est normalement de 60\% au minimum. L’application d’un tel seuil aux CGI identifiés pourrait représenter une amélioration supplémentaire du modèle. Les CGI sont souvent définis comme des régions d’un longueur de 140 paires de base, cependant certains auteurs indiquent qu’il existe une certaine variabilité qui rend cette définition éronée. Un seuil minimum de longueur a donc été suggéré par certains auteurs et il pourrait s’avérer intéressant de comparer les prédictions sans et avec son application, à faire avec caution \citep{Lan2009}. 

Une des limites des modèles de Markov cachés en général est la supposition que les distributions des paramètres d’observation suivent une loi géométrique.  \citep{Matthias2013} a identifié d’autres limitations de l’utilisation des modèles de Markov cachés, dans un context des prédictions des CGI. Parmi ces limitations se trouve le constat que les résultats d’un tel modèle dépendent fortement des probabilités initiales, ainsi que des itérations d'entraînement du modèle. Berg a donc suggéré l'entraînement du modèle, et la ré-estimation subséquente des probabilités initiales afin de mieux représenter les états cachés, et ceci pourrait également représenter une amélioration possible de notre modèle. 

Le détection précise des îlots CPG reste un sujet important dans un contexte médical, avec, parmi d’autres, de plus en plus d’associations identifiées entre le méthylation modifié et le cancer. Les régions se situant à moins de 20000 paires de base des frontières CGI, pour exemple, ont été identifiés comme des bons prédicteurs pour la location des régions qui subissent un méthylation modifié, spécifique aux cancers (“cancer-specific differentially methylated regions”) \citep{Irizarry2009}. L’amélioration des modèles qui nous permettent donc de prédire avec précision ces régions représentent un défi important dans la détection des cancers.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Ressources
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Ressources}

Ce document est disponible en ligne sous format ``.Rnw'', contenant tout le code néccessaire à la reproduction de l'analyse, réalisée avec un script en langage R \citep{RTeam2017}, ainsi que le jeu de données de départ. L'ensemble est situé sur Github : \url{https://github.com/gowachin/BeeMarkov} et peut être installé sur R via les commandes suivantes.

<<github_install , echo = T, eval=F>>=
# NOT RUN
library(devtools)
install_github("gowachin/BeeMarkov")
library(BeeMarkov)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Références
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage
\subsection*{Bibliographie}
\bibliographystyle{authordate1}
\bibliography{../../../../Mendeley/Markov}

\end{multicols}

\newpage
\subsection*{Annexes}

Représentation schématique de la structure du chromosome de souris numéro 1. Les modèles de Markov cachés permettent la détection des régions CpG+ (en bleu) versus les régions CpG- (en rouge). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (en vert) est encore visible. 

\begin{figure*}[!ht]%{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=\linewidth]{fig/mus1_s.jpg}
\end{center}
\caption{Représentation schématique de la structure du chromosome de souris numéro 1. Les modèles de Markov cachés permettent la détection des régions CpG+ (en bleu) versus les régions CpG- (en rouge). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (en vert) est encore visible. }
\label{fig:mus1_s}
\end{figure*}

\newpage

\begin{figure*}[!ht]%{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=\linewidth]{fig/mus2_s.jpg}
\end{center}
\caption{Représentation schématique de la structure du chromosome de souris numéro 2. Les modèles de Markov cachés permettent la détection des régions CpG+ (en bleu) versus les régions CpG- (en rouge). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (en vert) est encore visible. }
\label{fig:mus2_s}
\end{figure*}

\begin{figure*}[!ht]%{r}{0.6\linewidth}
\begin{center}
\includegraphics[width=\linewidth]{fig/mus3_s.jpg}
\end{center}
\caption{Représentation schématique de la structure du chromosome de souris numéro 3. Les modèles de Markov cachés permettent la détection des régions CpG+ (en bleu) versus les régions CpG- (en rouge). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (en vert) est encore visible.}
\label{fig:mus3_s}
\end{figure*}

\newpage

\begin{table*}
  \begin{center}
  \input{fig/mus1_t.tex}
  \end{center}
  \caption{Table récapitulative de la structure du chromosome de souris numéro 1. Les régions CpG+ (model = 1) versus les régions CpG- (model = 2). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (model = 3) est encore visible.}
  \label{tab:mus1_t}
\end{table*}  

\newpage

\begin{table*}
  \begin{center}
  \input{fig/mus2_t.tex}
  \end{center}
  \caption{Table récapitulative de la structure du chromosome de souris numéro 2. Les régions CpG+ (model = 1) versus les régions CpG- (model = 2). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (model = 3) est encore visible.}
  \label{tab:mus2_t}
\end{table*} 

\newpage

\begin{table*}
  \begin{center}
  \input{fig/mus3_t.tex}
  \end{center}
  \caption{Table récapitulative de la structure du chromosome de souris numéro 3. Les régions CpG+ (model = 1) versus les régions CpG- (model = 2). Le smoothing a été réalisé avec de valeurs de seuillage de s = 60 et r = 40, mais un certain marge de régions ambigües (model = 3) est encore visible.}
  \label{tab:mus3_t}
\end{table*}  


\newpage

\subsubsection*{scripts}
Les analyses ont été effectuées avec le code ci-dessous, sous Rstudio (Version 1.1.456) :
\todo[inline, color = red]{put script inside}
{\begin{lstlisting}
### R code from vignette source 'Markov_Report_Guerra_Jaunatre.Rnw'
### Encoding: UTF-8

###################################################
### code chunk number 1: packages
###################################################
library(xtable)
library(ggplot2)
library(reshape)
# library(plyr)
# library(MASS)
# library(ResourceSelection)
# library(ggpubr)
# library(tidyr)

if("BeeMarkov" %in% installed.packages()) {
  library(BeeMarkov)
}else{
  # library(devtools)
  # install_github("gowachin/BeeMarkov")
  # library(BeeMarkov)
}

library(seqinr)
rerun = FALSE


###################################################
### code chunk number 2: working (eval = FALSE)
###################################################
## setwd("manuscrit")
## 


###################################################
### code chunk number 3: transition
###################################################
transition <- function(file, # fichier
                       l_word = 1, # longueur des mots
                       n_seq = 1, # Nombre de sequences a analyser
                       log = TRUE,
                       type = "") {
  seq <-seqinr::read.fasta(file)
  Nseq <- length(seq)
  
  if (Nseq < n_seq) { # check if user want to input too many seq in the matrix learning
    stop(paste("n_seq is larger than the number of sequence in this file ( ", Nseq, " sequences for this file).", sep = ""))
  }
  
  l <- sapply(seq, length)
  if (l_word > min(l) | l_word >= 10) {
    stop("This is really too much for me, abort!!!")
  }

  tmp <-seqinr::count(seq[[1]], l_word) + 1 # add 1 occurence to have at least 1 obs
  
  cat(paste("      ============ Training model M",type,l_word," ============        \n", sep = ""))
  pb <- utils::txtProgressBar(min = 0, max = n_seq, style = 3)
  for (i in 2:n_seq) {
    utils::setTxtProgressBar(pb, i)
    
    tmp <- tmp +seqinr::count(seq[[i]], l_word)
  }
  close(pb)
  
  # # alternativ way, slower but prettier
  # cat(paste("      ============ Training model M",type,l_word," ============        \n", sep = ""))
  # l_count = function(Seq,n = l_word){count(Seq,n)} 
  # tmp <- rowSums(sapply(seq,l_count))
  
  if (l_word>1) {
    i <- 1
    wind = 4 
    for(j in 0:((length(tmp)/wind)-1)){
      tmp[(1+wind*j):(wind+wind*j)] <- tmp[(1+wind*j):(wind+wind*j)] * 4^(i-1) / sum(tmp[(1+wind*j):(wind+wind*j)] )
    }
    cat('      ============ Computing conditionnal probabilities ============        \n')
  } else {
    tmp = tmp / sum(tmp)
  }
  # possibility to compute without log
  if (log) {
    tmp = log(tmp)
  }
  return(tmp)
}

mP <-transition(file = "../raw_data/mus_cpg_app.fa", n_seq = 1160, l_word = 2, log = F)

mP <- matrix(mP, byrow = TRUE, ncol = 4, dimnames = list(unique(substr(names(mP),1,1)),unique(substr(names(mP),1,1))))

matable <- xtable(x = mP , label = "tab:trans")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/tab_trans.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")


###################################################
### code chunk number 4: threshold
###################################################
quality <- function(file, # fichier
                    pos_training = NULL, # file to train with for positive
                    neg_training = NULL, # file to train with for negative
                    trans_pos = NULL, #transition matrice pos
                    trans_neg = NULL, #transition matrice pos
                    l_word_pos = 1, # word lenght for transition table positif
                    l_word_neg = 1, # word length for transition table negatif
                    n_train = 1, # number of sequences to train with
                    n_seq = 1, # number of sequences to analyse
                    quiet = FALSE
){
  if(is.null(c(trans_pos,trans_neg))){
    trans_pos <-transition(file = pos_training, n_seq = n_train, l_word = l_word_pos, type ="+")
    trans_neg <- transition(file = neg_training, n_seq = n_train, l_word = l_word_neg, type = "-")
  } 
  
  seq <-seqinr::read.fasta(file)
  Nseq <- length(seq)
  
  if(Nseq < n_seq){ # check if user want to input too many seq in the matrix learning
    stop(paste("n_seq is larger than the number of sequence in this file ( ",Nseq," sequences for this file).", sep = ""))
  }
  
  result <- data.frame(VP = rep(FALSE,n_seq),
                       FN = rep(TRUE,n_seq),
                       pos = rep(NA,n_seq),
                       neg = rep(NA,n_seq)
  )
  
  p_init_pos = log(1/4^l_word_pos)
  p_init_neg = log(1/4^l_word_neg)
  
  if(!quiet) {cat('      ============ Computing sensi and speci for the test sequences ============       \n')
    pb <- utils::txtProgressBar(min = 0, max = n_seq, style = 3)}
  for(i in 1:n_seq){
    if(!quiet) utils::setTxtProgressBar(pb, i)
    n_word_pos <-seqinr::count(seq[[i]], l_word_pos)
    n_word_neg <-seqinr::count(seq[[i]], l_word_neg)
    result$pos[i] <- p_init_pos + sum( trans_pos * n_word_pos )
    result$neg[i] <- p_init_neg + sum( trans_neg * n_word_neg )
    if(result$pos[i] > result$neg[i]){
      result$VP[i] <- TRUE ; result$FN[i] <- FALSE 
    } else { 
      result$VP[i] <- FALSE ; result$FN[i] <- TRUE
    }
  }
  if(!quiet) close(pb)
  
  tmp <- colSums(result[,1:2])
  return(tmp)
}

threshold <- function(pos_test, # fichier
                     neg_test,
                     pos_training, # file to train with for positive
                     neg_training, # file to train with for negative
                     pos_seq = c(1:2),
                     neg_seq = c(1:2),
                     n_train = 1, # number of sequences to train with
                     n_seq = 1 # number of sequences to analyse
){
  
  # choix =utils::menu(c("yes","no"),
  #              title = "You will launch long computation, do you wish to procede further ?")
  # if (choix ==1) cat("\n      ============ Go take a good coffee ============       \n\n")
  # if (choix ==2) stop("You stopped the computations")
  
  
  trans_pos <- list()
  trans_neg <- list()
  
  cat('\n      ============ Training modeles ============       \n\n')
  for(i in pos_seq){
    trans_pos[[i]] <- transition(file = pos_training, n_seq = n_train, l_word = i, type = "+")
  }
  cat('\n')
  for(j in neg_seq){
    trans_neg[[j]] <- transition(file = neg_training, n_seq = n_train, l_word = j, type = "-")
  }
  
  cat('\n      ============ Training modeles ============       \n\n')    
  sensi <- speci <- matrix(rep(0,length(pos_seq)*length(neg_seq)),ncol = length(pos_seq),nrow = length(neg_seq))
  for(i in pos_seq){
    for(j in neg_seq){
      cat('\n')
      cat(paste("      ============ Model M+ (",i,"/",j,") ============        \n", sep = ""))
      pos <- quality(file = pos_test, # fichier
                     trans_pos = trans_pos[[i]], #transition matrice pos
                     trans_neg = trans_neg[[j]], #transition matrice neg
                     l_word_pos = i, # transition table positif
                     l_word_neg = j, # transition table negatif
                     n_train = n_train, # number of sequences to train with
                     n_seq = n_seq, # number of sequences to analyse
                     quiet = TRUE
      )
      cat(paste("      ============ Model M- (",i,"/",j,") ============        \n", sep = ""))
      neg <- quality(file = neg_test, # fichier
                     trans_pos = trans_pos[[i]], #transition matrice pos
                     trans_neg = trans_neg[[j]], #transition matrice neg
                     l_word_pos = i, # transition table positif
                     l_word_neg = j, # transition table negatif
                     n_train = n_train, # number of sequences to train with
                     n_seq = n_seq, # number of sequences to analyse
                     quiet = TRUE
      )
      
      sensi[i,j] <- pos[1] / sum(pos)
      speci[i,j] <- neg[2] / sum(neg)
      
    }
  }
  
  cat(paste("      ============ Come back from your coffee ============        \n", sep = ""))
  colnames(sensi) <- colnames(speci) <- paste("-",neg_seq, sep="")
  rownames(sensi) <- rownames(speci) <- paste("+",pos_seq, sep="")
  
  final <-list(sensi,speci) ; names(final) = c("sensi","speci")
  
  return(final)
}



###################################################
### code chunk number 5: seuil
###################################################
if("final.RData" %in% list.files("fig/") && !rerun){
  load("fig/final.RData")
}else{
  final <- threshold("../raw_data/mus_cpg_test.fa", # fichier
  "../raw_data/mus_tem_test.fa",
  "../raw_data/mus_cpg_app.fa", # file to train with for positive
  "../raw_data/mus_tem_app.fa", # file to train with for negative
  pos_seq = c(1:6),
  neg_seq = c(1:6),
  n_train = 1160, # number of sequences to train with
  n_seq = 1163 # number of sequences to analyse
)
save(final,file = "fig/final.RData")
}

table <- cbind(melt(final$sensi), melt(final$speci)[, 3])
colnames(table) <- c("M", "m", "Sensi", "Speci")
table$score <- table$Sensi + table$Speci

visual <- ggplot(table, aes(M, m)) +
  geom_raster(aes(fill = score), hjust = 0.5, vjust = 0.5, interpolate = FALSE) +
  geom_contour(aes(z = score)) + xlab("CpG+") + ylab("CpG-")
visual
ggsave('visual.pdf', plot = visual, device = "pdf", path = 'fig/',scale = 3, width = 7, height = 4, units = "cm", limitsize = T)
rm(visual)

table[which(table$tot == max(table$tot)),]


###################################################
### code chunk number 6: trans_mod
###################################################
  l_c <- 1 / 1000
  l_nc <- 1 / 125000
  
   trans_mod <- log(matrix(c(
    1 - l_c, l_nc,
    l_c, 1 - l_nc
  ),
  ncol = 2, nrow = 2 , dimnames = list(c("M+","M-"),c("M+","M-"))
  ))

matable <- xtable(x = trans_mod , label = "tab:trans_mod")
# Notez les doubles \\ nécessaires dans R, c'est la "double escape rule"
print(matable, file = "fig/trans_mod.tex",size = "tiny", NA.string = "NA",
      table.placement = "!t",
      floating = FALSE,
      caption.placement="top",
      include.rownames = TRUE,
      include.colnames = TRUE,
      latex.environments = "center")


###################################################
### code chunk number 7: viterbi
###################################################
viterbi <- function(file,
                    pos_training = "../raw_data/mus_cpg_app.fa", # file to train with for positive
                    neg_training = "../raw_data/mus_tem_app.fa", # file to train with for negative
                    l_word_pos = 1,
                    l_word_neg = 1,
                    n_train = 1160,
                    n_ana = 1,
                    l_c = 1000, # length coding
                    l_nc = 125000 # length non-coding
) {
  trans_pos <- transition(file = pos_training, n_seq = n_train, l_word = l_word_pos, type = "+")
  trans_neg <- transition(file = neg_training, n_seq = n_train, l_word = l_word_neg, type = "-")
  
  seq <- seqinr::read.fasta(file)
  if (n_ana > 1) stop("Analysis for multiple files is not implemented yet")
  
  raw_seq <- seq[[1]]
  long <- length(raw_seq)
  
  beg <- max(l_word_pos, l_word_neg)
  
  # compute p_initial and transition matrix for markov
  pos_init <- neg_init <- log(0.5)
  l_c <- 1 / l_c
  l_nc <- 1 / l_nc
  
  trans_mod <- log(matrix(c(
    1 - l_c, l_nc,
    l_c, 1 - l_nc
  ),
  ncol = 2, nrow = 2
  ))
  colnames(trans_mod) <- rownames(trans_mod) <- c("c", "nc")
  
  # initialisation
  ncol <- 7
  proba <- matrix(rep(NA, long * ncol), ncol = ncol)
  colnames(proba) <- c("M+", "M-", "model", "length", "rep_length", "begin", "end")
  
  # time explode if it is not a matrix anymore !!!
  # proba <- as.data.frame(proba)
  
  # old version is v2 takes too long
  # v1 = function(){
  # trans_pos[which(names(trans_pos)==paste(raw_seq[(beg-l_word_pos+1):beg],collapse = ""))]
  # }
  # v2 = function(){
  # min(count(raw_seq[(beg-l_word_pos+1):beg], l_word_pos) * trans_pos)
  # }
  # system.time(v1())
  # system.time(v2())
  
  # compute first base and initiate Viterbi
  proba[beg, "M+"] <- trans_pos[which(names(trans_pos) == paste(raw_seq[(beg - l_word_pos + 1):beg], collapse = ""))] + pos_init
  proba[beg, "M-"] <- trans_neg[which(names(trans_neg) == paste(raw_seq[(beg - l_word_neg + 1):beg], collapse = ""))] + neg_init
  if (proba[beg, "M+"] > proba[beg, "M-"]) {
    proba[beg, "model"] <- 1
  } else {
    proba[beg, "model"] <- 2
  }
  proba[beg, c("length", "rep_length")] <- 1
  tmp <- proba[beg, c(6, 7)] <- beg
  proba[1:beg - 1, "rep_length"] <- beg - 1
  proba[1:beg - 1, "model"] <- 3
  proba[1, "begin"] <- 1
  proba[beg - 1, c(4, 7)] <- beg - 1
  
  beg <- beg + 1
  cat("\n      ============ Viterbi is running ============       \n\n")
  pb <- utils::txtProgressBar(min = beg, max = long, style = 3)
  for (i in beg:long) {
    utils::setTxtProgressBar(pb, i)
    
    # proba d'avoir la base sous M
    pM <- trans_pos[which(names(trans_pos) == paste(raw_seq[(i - l_word_pos + 1):i], collapse = ""))] + max(
      proba[i - 1, "M+"] + trans_mod[1, 1],
      proba[i - 1, "M-"] + trans_mod[2, 1]
    )
    
    # proba d'avoir la base sous m
    pm <- trans_neg[which(names(trans_neg) == paste(raw_seq[(i - l_word_neg + 1):i], collapse = ""))] + max(
      proba[i - 1, "M-"] + trans_mod[2, 2],
      proba[i - 1, "M+"] + trans_mod[1, 2]
    )
    
    proba[i, "M+"] <- pM
    proba[i, "M-"] <- pm
    
    if (proba[i, "M+"] > proba[i, 2]) {
      proba[i, "model"] <- 1
    } else {
      proba[i, "model"] <- 2
    }
    # length information
    if (proba[i, "model"] == proba[i - 1, "model"]) {
      proba[i, "length"] <- proba[i - 1, "length"] + 1 # increase part length
      proba[i - 1, c(4, 7)] <- NA # erase length in previous ligne
    } else {
      proba[i, "length"] <- 1 # initiate new part length
      proba[i - 1, "end"] <- i - 1 # put end value of precedent part
      proba[c(tmp:(i - 1)), "rep_length"] <- proba[i - 1, "length"] # rep value of length for precedent part
      proba[i, "begin"] <- tmp <- i # put begin value of the actual part
    }
  }
  close(pb)
  
  # closing table
  proba[i, "end"] <- i # put end value of precedent part
  proba[c(tmp:(i)), "rep_length"] <- proba[i, "length"] # rep value of length for precedent part
  
  # add a column for the line number
  proba <- cbind(c(1:dim(proba)[1]), proba)
  colnames(proba)[1] <- "n"
  
  return(proba)
}


###################################################
### code chunk number 8: smoothing
###################################################
smoothing <- function(seq,
                      l_word_pos = 5,
                      l_word_neg = 4,
                      smooth_win = 10,
                      reject_win = 1) {
  beg <- max(l_word_pos, l_word_neg)

  # finding ambiguous regions which are shorter than a certain windows
  cat("      ============ Smoothing ============       \n")
  seq <- cbind(seq, seq[, 4])
  colnames(seq)[9] <- c("smoothed")
  seq[which(seq[, "rep_length"] <= smooth_win), "smoothed"] <- 3

  # old version is v1 takes too long
  # v1 = function(){
  #   cat("      ============ Smoothing boucle ============       \n")
  #   pb <- utils::txtProgressBar(min = 1, max = max(seq[, 1]), style = 3)
  #   for (i in 1:dim(seq)[1]) {
  #     utils::setTxtProgressBar(pb, i)
  #     if (seq[i, 6] <= smooth_win) {
  #       seq[i, "smoothed"] <- 3
  #     }
  #   }
  #   close(pb)
  # }
  # v2 = function(){
  #   seq[which(seq[, 6] <= smooth_win), "smoothed"] <- 3}
  # system.time(v1())
  # system.time(v2())
  
  # unified ambiguous regions
  seq <- cbind(seq, seq[, c(5:8)])
  colnames(seq)[10:13] <- paste("S_", colnames(seq[, c(10:13)]), sep = "")

  seq[beg, "S_length"] <- 1
  tmp <- seq[beg, c("S_begin", "S_end")] <- beg
  seq[-c(1:beg), c(10:13)] <- NA

  beg <- beg + 1
  cat("\n      ============ Smoothing length ============      \n")
  pb <- utils::txtProgressBar(min = beg - 1, max = dim(seq)[1], style = 3)
  for (i in beg:dim(seq)[1]) {
    utils::setTxtProgressBar(pb, i)
    if (seq[i, "smoothed"] == seq[i - 1, "smoothed"]) {
      seq[i, "S_length"] <- seq[i - 1, "S_length"] + 1 # increase part length
      seq[i - 1, c("S_length", "S_end")] <- NA # erase length in previous ligne
    } else {
      seq[i, "S_length"] <- 1 # initiate new part length
      seq[i - 1, "S_end"] <- i - 1 # put end value of precedent part
      seq[c(tmp:(i - 1)), "S_rep_length"] <- seq[i - 1, "S_length"] # rep value of length for precedent part
      seq[i, "S_begin"] <- tmp <- i # put begin value of the actual part
    }
  }
  close(pb)

  # closing table
  seq[i, 13] <- i # put end value of precedent part
  seq[c(tmp:(i)), 11] <- seq[i, 10] # rep value of length for precedent part
  
  # to reject some region and put arbitrary models on them
  if(reject_win > 1){
    colnames(seq)[10:13] <- paste("R_", colnames(seq[, c(10:13)]), sep = "")
    
    head(seq)
    
    cat("      ============ Rejecting ============      \n")
    # finding regions of length < reject_win between tho regions of same model. Changing the model to surrounding
    solo_l <-seq[which(seq[,"R_S_length"] %in% unique(seq[, "R_S_rep_length"])),c("smoothed","R_S_rep_length")]
    for(i in 2:(dim(solo_l)[1]-1)){
      if(solo_l[i-1,1]==solo_l[i+1,1] && solo_l[i,2] < reject_win && solo_l[i,1] == 3) {solo_l[i,1] <- solo_l[i-1,1]}
    }
    
    seq[,"smoothed"] <- rep(solo_l[,1],solo_l[,2])
    
    beg <- beg - 1
    
    seq[beg, "R_S_length"] <- 1
    tmp <- seq[beg, c("R_S_begin", "R_S_end")] <- beg
    seq[-c(1:beg), c(10:13)] <- NA
    
    beg <- beg + 1
    seq[-c(1:beg), c(10:13)] <- NA
    cat("\n      ============ Smoothing length after reject ============      \n")
    pb <- utils::txtProgressBar(min = beg - 1, max = dim(seq)[1], style = 3)
    for (i in beg:dim(seq)[1]) {
      utils::setTxtProgressBar(pb, i)
      if (seq[i, "smoothed"] == seq[i - 1, "smoothed"]) {
        seq[i, "R_S_length"] <- seq[i - 1, "R_S_length"] + 1 # increase part length
        seq[i - 1, c("R_S_length", "R_S_end")] <- NA # erase length in previous ligne
      } else {
        seq[i, "R_S_length"] <- 1 # initiate new part length
        seq[i - 1, "R_S_end"] <- i - 1 # put end value of precedent part
        seq[c(tmp:(i - 1)), "R_S_rep_length"] <- seq[i - 1, "R_S_length"] # rep value of length for precedent part
        seq[i, "R_S_begin"] <- tmp <- i # put begin value of the actual part
      }
    }
    close(pb)
    
    # closing table
    seq[i, 13] <- i # put end value of precedent part
    seq[c(tmp:(i)), 11] <- seq[i, 10] # rep value of length for precedent part
    
  }
  
  return(seq)
}


###################################################
### code chunk number 9: plot_resume
###################################################
graph <- function(seq,colors = c("blue","red","green"),nrow = 3,ycol = 4){
  par(mfrow = c(nrow,1), mar = c(3,2,1,1))
  # c(5, 4, 4, 2)
  
  long <- max(seq[,1])/nrow
  for(i in 0:(nrow-1)){
    plot(x = seq[((1+long*i):(long+long*i)),1],
         y = seq[((1+long*i):(long+long*i)),ycol],
         col = colors[seq[((1+long*i):(long+long*i)),9]], xlab = " ", ylab = " ")
  }
  par(mfrow = c(1,1))
}

resume <- function(seq){
  beg <- seq[which(!is.na(seq[,12])),12] 
  end <- seq[which(!is.na(seq[,13])),13]
  long <- seq[which(!is.na(seq[,10])),10]
  model <- seq[which(!is.na(seq[,10])),9]
  length(beg) ; length((end)) ; length(long) ; length(model)
  
  table <- data.frame(beg,end,long,model)
  return(table)
}


###################################################
### code chunk number 10: mus1
###################################################
if("mus1.RData" %in% list.files("fig/") && !rerun){
  load("fig/mus1.RData")
}else{
mus1 <- viterbi(file = "../raw_data/mus1.fa",
  l_word_pos = 5,
  l_word_neg = 4
)
save(mus1,file = "fig/mus1.RData")
}

mus1 <- smoothing(mus1,5,4,60, 40)

jpeg("fig/mus1_s.jpg", width = 836, height = 496)
# 2. Create the plot
graph(mus1,nrow = 3, ycol = 9)
# 3. Close the file
dev.off()

mus1_t <- resume(mus1)



###################################################
### code chunk number 11: mus2
###################################################
if("mus2.RData" %in% list.files("fig/") && !rerun){
  load("fig/mus2.RData")
}else{
mus2 <- viterbi(file = "../raw_data/mus2.fa",
  l_word_pos = 5,
  l_word_neg = 4
)
save(mus2,file = "fig/mus2.RData")
}

mus2 <- smoothing(mus2,5,4,60, 40)

jpeg("fig/mus2_s.jpg", width = 836, height = 496)
# 2. Create the plot
graph(mus2,nrow = 3, ycol = 9)
# 3. Close the file
dev.off()

mus2_t <- resume(mus2)



###################################################
### code chunk number 12: mus3
###################################################
if("mus3.RData" %in% list.files("fig/") && !rerun){
  load("fig/mus3.RData")
}else{
mus3 <- viterbi(file = "../raw_data/mus3.fa",
  l_word_pos = 5,
  l_word_neg = 4
)
save(mus3,file = "fig/mus3.RData")
}

mus3 <- smoothing(mus3,5,4,60, 40)

jpeg("fig/mus3_s.jpg", width = 836, height = 496)
# 2. Create the plot
graph(mus3,nrow = 3, ycol = 9)
# 3. Close the file
dev.off()

mus3_t <- resume(mus3)


###################################################
### code chunk number 13: github_install (eval = FALSE)
###################################################
## # NOT RUN
## library(devtools)
## install_github("gowachin/BeeMarkov")
## library(BeeMarkov)


\end{lstlisting}}
%\end{multicols}

\end{document}
